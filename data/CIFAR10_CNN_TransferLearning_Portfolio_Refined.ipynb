{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU",
  "portfolio_refined": true
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR-10 Image Classification with CNNs and Transfer Learning (VGG16)\n\n**Author:** Oghenevurie Lauretta  \n**Focus:** Applied Deep Learning (Computer Vision) \u2014 portfolio project\n\n## Executive summary\nThis notebook builds and evaluates image classification models on the CIFAR-10 dataset (10 object categories).  \nIt starts with a **baseline CNN** and then uses **transfer learning (VGG16)** to demonstrate how pre-trained feature extractors can improve performance and training efficiency.\n\n## Why this matters (healthcare / applied AI angle)\nThe workflow here (data pipelines \u2192 model training \u2192 robust evaluation \u2192 error analysis) maps directly to real-world image classification problems, including **medical imaging** tasks (e.g., triage, quality control, and decision-support), where **class-level performance and error patterns** are as important as overall accuracy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and reproducibility\nWe set seeds for reproducibility and import required libraries."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Core\nimport os\nimport random\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# ML / DL\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\n\n# Metrics\nfrom sklearn.metrics import classification_report, confusion_matrix\n\n# Reproducibility\nSEED = 42\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntf.random.set_seed(SEED)\n\nprint(\"TensorFlow:\", tf.__version__)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load CIFAR-10 and create train/validation split\nCIFAR-10 consists of 60,000 32\u00d732 colour images across 10 classes (50,000 train / 10,000 test). We'll create a validation split from the training set."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from tensorflow.keras.datasets import cifar10\nfrom sklearn.model_selection import train_test_split\n\n# Load dataset\n(x_train_full, y_train_full), (x_test, y_test) = cifar10.load_data()\n\n# Train/val split\nx_train, x_val, y_train, y_val = train_test_split(\n    x_train_full, y_train_full, test_size=0.10, random_state=SEED, stratify=y_train_full\n)\n\n# Normalise to [0, 1]\nx_train = x_train.astype(\"float32\") / 255.0\nx_val   = x_val.astype(\"float32\") / 255.0\nx_test  = x_test.astype(\"float32\") / 255.0\n\nclass_names = ['airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck']\n\nprint(\"Train:\", x_train.shape, y_train.shape)\nprint(\"Val:  \", x_val.shape, y_val.shape)\nprint(\"Test: \", x_test.shape, y_test.shape)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Quick data sanity check\nWe visualise a few training images and their labels."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(8, 8))\nfor i in range(9):\n    plt.subplot(3, 3, i+1)\n    plt.imshow(x_train[i])\n    plt.title(class_names[int(y_train[i])])\n    plt.axis(\"off\")\nplt.tight_layout()\nplt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Helper functions (evaluation + error analysis)\nThese utilities standardise evaluation so results are consistent across models (matching a 'prediction project' format)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def plot_history(history, title=\"Training curves\"):\n    plt.figure(figsize=(8, 5))\n    plt.plot(history.history.get(\"accuracy\", []), label=\"Train accuracy\")\n    plt.plot(history.history.get(\"val_accuracy\", []), label=\"Val accuracy\")\n    plt.title(title)\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Accuracy\")\n    plt.legend()\n    plt.show()\n\n    plt.figure(figsize=(8, 5))\n    plt.plot(history.history.get(\"loss\", []), label=\"Train loss\")\n    plt.plot(history.history.get(\"val_loss\", []), label=\"Val loss\")\n    plt.title(title.replace(\"accuracy\", \"loss\"))\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Loss\")\n    plt.legend()\n    plt.show()\n\ndef plot_confusion_matrix(cm, labels, title=\"Confusion matrix\"):\n    plt.figure(figsize=(8, 6))\n    plt.imshow(cm, interpolation=\"nearest\")\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(labels))\n    plt.xticks(tick_marks, labels, rotation=45, ha=\"right\")\n    plt.yticks(tick_marks, labels)\n    plt.ylabel(\"True label\")\n    plt.xlabel(\"Predicted label\")\n    plt.tight_layout()\n    plt.show()\n\ndef evaluate_classifier(model, x, y, labels, batch_size=128, title_prefix=\"Model\"):\n    # Predict\n    probs = model.predict(x, batch_size=batch_size, verbose=0)\n    y_pred = np.argmax(probs, axis=1)\n    y_true = y.reshape(-1)\n\n    # Confusion matrix + report\n    cm = confusion_matrix(y_true, y_pred)\n    print(f\"\\n{title_prefix} \u2014 Classification report:\")\n    print(classification_report(y_true, y_pred, target_names=labels, digits=4))\n    plot_confusion_matrix(cm, labels, title=f\"{title_prefix} \u2014 Confusion matrix\")\n\n    return y_true, y_pred, probs\n\ndef show_misclassifications(x, y_true, y_pred, labels, n=12):\n    wrong = np.where(y_true != y_pred)[0]\n    if len(wrong) == 0:\n        print(\"No misclassifications found.\")\n        return\n\n    n = min(n, len(wrong))\n    picks = np.random.choice(wrong, size=n, replace=False)\n\n    plt.figure(figsize=(10, 7))\n    cols = 4\n    rows = int(np.ceil(n / cols))\n    for i, idx in enumerate(picks, start=1):\n        plt.subplot(rows, cols, i)\n        plt.imshow(x[idx])\n        plt.title(f\"T: {labels[y_true[idx]]}\\nP: {labels[y_pred[idx]]}\", fontsize=9)\n        plt.axis(\"off\")\n    plt.tight_layout()\n    plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Baseline model: Convolutional Neural Network (CNN)\nWe build a straightforward CNN with dropout + batch normalisation. This serves as the baseline for comparison."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def build_cnn(input_shape=(32, 32, 3), num_classes=10):\n    model = keras.Sequential([\n        layers.Conv2D(32, (3, 3), padding=\"same\", activation=\"relu\", input_shape=input_shape),\n        layers.BatchNormalization(),\n        layers.Conv2D(32, (3, 3), padding=\"same\", activation=\"relu\"),\n        layers.BatchNormalization(),\n        layers.MaxPooling2D(),\n        layers.Dropout(0.25),\n\n        layers.Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\"),\n        layers.BatchNormalization(),\n        layers.Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\"),\n        layers.BatchNormalization(),\n        layers.MaxPooling2D(),\n        layers.Dropout(0.30),\n\n        layers.Flatten(),\n        layers.Dense(256, activation=\"relu\"),\n        layers.Dropout(0.40),\n        layers.Dense(num_classes, activation=\"softmax\")\n    ])\n\n    model.compile(\n        optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n        loss=\"sparse_categorical_crossentropy\",\n        metrics=[\"accuracy\"]\n    )\n    return model\n\ncnn = build_cnn()\ncnn.summary()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5B. Train the CNN\nWe include early stopping to reduce overfitting and keep training time reasonable."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "early_stop = keras.callbacks.EarlyStopping(\n    monitor=\"val_accuracy\", patience=5, restore_best_weights=True\n)\n\nhistory_cnn = cnn.fit(\n    x_train, y_train,\n    validation_data=(x_val, y_val),\n    epochs=30,\n    batch_size=64,\n    callbacks=[early_stop],\n    verbose=1\n)\n\nplot_history(history_cnn, title=\"CNN training curves\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5C. CNN evaluation on the test set\nWe evaluate beyond accuracy: confusion matrix, class-level precision/recall/F1, and misclassifications."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "cnn_test_loss, cnn_test_acc = cnn.evaluate(x_test, y_test, verbose=0)\nprint(f\"CNN test accuracy: {cnn_test_acc:.4f} | test loss: {cnn_test_loss:.4f}\")\n\ny_true_cnn, y_pred_cnn, probs_cnn = evaluate_classifier(\n    cnn, x_test, y_test, class_names, title_prefix=\"CNN\"\n)\n\nshow_misclassifications(x_test, y_true_cnn, y_pred_cnn, class_names, n=12)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Transfer learning: VGG16 feature extractor\nWe reuse ImageNet-learned features from VGG16. Because CIFAR-10 images are 32\u00d732, we resize to 224\u00d7224 and apply `preprocess_input`.\n\n> Note: Transfer learning is commonly used in applied settings (including medical imaging) where labelled data may be limited and strong pre-trained features improve performance."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from tensorflow.keras.applications import VGG16\nfrom tensorflow.keras.applications.vgg16 import preprocess_input\n\nIMG_SIZE = 224\nBATCH = 64\n\ndef make_ds(X, y, batch=BATCH, shuffle=False):\n    ds = tf.data.Dataset.from_tensor_slices((X, y))\n    if shuffle:\n        ds = ds.shuffle(buffer_size=len(X), seed=SEED)\n    ds = ds.map(lambda img, lab: (tf.image.resize(img, (IMG_SIZE, IMG_SIZE)), lab),\n                num_parallel_calls=tf.data.AUTOTUNE)\n    ds = ds.map(lambda img, lab: (preprocess_input(img), lab),\n                num_parallel_calls=tf.data.AUTOTUNE)\n    ds = ds.batch(batch).prefetch(tf.data.AUTOTUNE)\n    return ds\n\ntrain_ds = make_ds(x_train, y_train, shuffle=True)\nval_ds   = make_ds(x_val, y_val, shuffle=False)\ntest_ds  = make_ds(x_test, y_test, shuffle=False)\n\nprint(\"Prepared tf.data pipelines.\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6B. Build and train the transfer learning model (frozen base)\nWe freeze the VGG16 convolutional base and train a small classification head first."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "base = VGG16(weights=\"imagenet\", include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\nbase.trainable = False\n\ninputs = keras.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\nx = base(inputs, training=False)\nx = layers.GlobalAveragePooling2D()(x)\nx = layers.Dropout(0.3)(x)\noutputs = layers.Dense(10, activation=\"softmax\")(x)\n\nvgg_frozen = keras.Model(inputs, outputs)\n\nvgg_frozen.compile(\n    optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n    loss=\"sparse_categorical_crossentropy\",\n    metrics=[\"accuracy\"]\n)\n\nvgg_frozen.summary()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "early_stop_vgg = keras.callbacks.EarlyStopping(\n    monitor=\"val_accuracy\", patience=5, restore_best_weights=True\n)\n\nhistory_vgg_frozen = vgg_frozen.fit(\n    train_ds,\n    validation_data=val_ds,\n    epochs=15,\n    callbacks=[early_stop_vgg],\n    verbose=1\n)\n\nplot_history(history_vgg_frozen, title=\"VGG16 (frozen) training curves\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6C. Optional fine-tuning\nIf validation performance plateaus, we can unfreeze the top layers of VGG16 and continue training with a smaller learning rate."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Unfreeze top convolutional block(s) for fine-tuning\nbase.trainable = True\n\n# Freeze earlier layers to keep low-level features stable\nfor layer in base.layers[:-16]:\n    layer.trainable = False\n\nvgg_finetuned = keras.Model(inputs, outputs)\n\nvgg_finetuned.compile(\n    optimizer=keras.optimizers.Adam(learning_rate=1e-5),\n    loss=\"sparse_categorical_crossentropy\",\n    metrics=[\"accuracy\"]\n)\n\nearly_stop_ft = keras.callbacks.EarlyStopping(\n    monitor=\"val_accuracy\", patience=4, restore_best_weights=True\n)\n\nhistory_vgg_ft = vgg_finetuned.fit(\n    train_ds,\n    validation_data=val_ds,\n    epochs=10,\n    callbacks=[early_stop_ft],\n    verbose=1\n)\n\nplot_history(history_vgg_ft, title=\"VGG16 (fine-tuned) training curves\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Evaluate and compare models\nWe compute test accuracy for each model and review class-level performance for the strongest model."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Evaluate on test set\ncnn_test_loss, cnn_test_acc = cnn.evaluate(x_test, y_test, verbose=0)\nvgg_frozen_loss, vgg_frozen_acc = vgg_frozen.evaluate(test_ds, verbose=0)\n\n# Fine-tuned model may not have been run; guard accordingly\nvgg_ft_acc = None\ntry:\n    vgg_ft_loss, vgg_ft_acc = vgg_finetuned.evaluate(test_ds, verbose=0)\nexcept Exception as e:\n    print(\"Fine-tuned model not evaluated (likely not trained yet).\")\n\nprint(f\"CNN test accuracy:         {cnn_test_acc:.4f}\")\nprint(f\"VGG16 frozen test accuracy:{vgg_frozen_acc:.4f}\")\nif vgg_ft_acc is not None:\n    print(f\"VGG16 fine-tuned accuracy: {vgg_ft_acc:.4f}\")\n\n# Choose best available model for deeper evaluation\nbest_model = vgg_finetuned if vgg_ft_acc is not None else vgg_frozen\nbest_name  = \"VGG16 fine-tuned\" if vgg_ft_acc is not None else \"VGG16 frozen\"\n\n# For evaluate_classifier we need arrays; create predictions from ds\nprobs_best = best_model.predict(test_ds, verbose=0)\ny_pred_best = np.argmax(probs_best, axis=1)\ny_true_best = y_test.reshape(-1)\n\ncm_best = confusion_matrix(y_true_best, y_pred_best)\nprint(f\"\\n{best_name} \u2014 Classification report:\")\nprint(classification_report(y_true_best, y_pred_best, target_names=class_names, digits=4))\nplot_confusion_matrix(cm_best, class_names, title=f\"{best_name} \u2014 Confusion matrix\")\nshow_misclassifications(x_test, y_true_best, y_pred_best, class_names, n=12)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Conclusion (portfolio-ready)\n**Key takeaways**\n- A baseline CNN provides a strong starting point for CIFAR-10 classification.\n- Transfer learning with VGG16 demonstrates how pre-trained features can accelerate learning and improve performance in applied scenarios.\n- Class-level metrics and misclassification analysis reveal where the model is most reliable and where it struggles\u2014critical for real-world deployment.\n\n**Next steps**\n- Add data augmentation (random flips/crops) and systematic hyperparameter tuning.\n- Try modern architectures (ResNet/EfficientNet) and compare.\n- Package the best model for inference (saved model + simple prediction script) and document results in the repository README."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Save trained models\nSaving models makes your repository reproducible. Commit large model files only if your repo policy allows; otherwise, upload to a release or cloud storage and link in the README."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Save baseline CNN\ncnn.save(\"cnn_cifar10_lauretta.keras\")\nprint(\"Saved: cnn_cifar10_lauretta.keras\")\n\n# Save VGG16 models (if trained)\ntry:\n    vgg_frozen.save(\"vgg16_frozen_cifar10_lauretta.keras\")\n    print(\"Saved: vgg16_frozen_cifar10_lauretta.keras\")\nexcept Exception:\n    pass\n\ntry:\n    vgg_finetuned.save(\"vgg16_finetuned_cifar10_lauretta.keras\")\n    print(\"Saved: vgg16_finetuned_cifar10_lauretta.keras\")\nexcept Exception:\n    pass\n"
   ],
   "outputs": [],
   "execution_count": null
  }
 ]
}